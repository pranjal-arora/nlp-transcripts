# -*- coding: utf-8 -*-
"""PranjalArora_102003402_NLP in Python - 4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vrOQVVVOZUND5WT5p67OYFv4YXKXjzpc

# Sentiment Analysis

## Introduction

So far, all of the analysis we've done has been pretty generic - looking at counts, creating scatter plots, etc. These techniques could be applied to numeric data as well.

When it comes to text data, there are a few popular techniques that we'll be going through in the next few notebooks, starting with sentiment analysis. A few key points to remember with sentiment analysis.

1. **TextBlob Module:** Linguistic researchers have labeled the sentiment of words based on their domain expertise. Sentiment of words can vary based on where it is in a sentence. The TextBlob module allows us to take advantage of these labels.
2. **Sentiment Labels:** Each word in a corpus is labeled in terms of polarity and subjectivity (there are more labels as well, but we're going to ignore them for now). A corpus' sentiment is the average of these.
   * **Polarity**: How positive or negative a word is. -1 is very negative. +1 is very positive.
   * **Subjectivity**: How subjective, or opinionated a word is. 0 is fact. +1 is very much an opinion.

For more info on how TextBlob coded up its [sentiment function](https://planspace.org/20150607-textblob_sentiment/).

Let's take a look at the sentiment of the various transcripts, both overall and throughout the comedy routine.

## Sentiment of Routine
"""

# We'll start by reading in the corpus, which preserves word order
import pandas as pd

data = pd.read_pickle('/content/sample_data/corpus.pkl') #previous corpus file of assignment 2
data

# Create quick lambda functions to find the polarity and subjectivity of each routine

# Terminal / Anaconda Navigator: conda install -c conda-forge textblob

from textblob import TextBlob #Textblob is used to process text. It provides a simple API 
#to common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more


#The sentiment property returns a namedtuple of the form Sentiment(polarity, subjectivity). 
#The polarity score is a float within the range [-1.0, 1.0]. 
#The subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective.
pol = lambda x: TextBlob(x).sentiment.polarity
sub = lambda x: TextBlob(x).sentiment.subjectivity

data['polarity'] = data['transcript'].apply(pol)
data['subjectivity'] = data['transcript'].apply(sub)
data

# Let's plot the results
import matplotlib.pyplot as plt

plt.rcParams['figure.figsize'] = [10, 8]

for index, comedian in enumerate(data.index):
    x = data.polarity.loc[comedian] #plot polarity on x
    y = data.subjectivity.loc[comedian] #plot subjectivity on y
    plt.scatter(x, y, color='blue')
    plt.text(x+.001, y+.001, data['full_name'][index], fontsize=10)
    plt.xlim(-.01, .12) 
    
plt.title('Sentiment Analysis', fontsize=20)
plt.xlabel('<-- Negative -------- Positive -->', fontsize=15)
plt.ylabel('<-- Facts -------- Opinions -->', fontsize=15)

plt.show()

"""## Sentiment of Routine Over Time

Instead of looking at the overall sentiment, let's see if there's anything interesting about the sentiment over time throughout each routine.
"""

# Split each routine into 10 parts -so that we can look at them over time

import numpy as np
import math

def split_text(text, n=10):
    #Takes in a string of text, and splits into n equal parts

    # Calculate length of text, the size of each chunk of text and the starting points of each chunk of text
    length = len(text)
    size = math.floor(length / n)
    start = np.arange(0, length, size)
    
    # Pull out equally sized pieces of text and put it into a list
    split_list = []
    for piece in range(n):
        split_list.append(text[start[piece]:start[piece]+size])
    return split_list

# Let's take a look at our data again
data

# Let's create a list to hold all of the pieces of text
list_pieces = []
for t in data.transcript:
    split = split_text(t)
    list_pieces.append(split)
    
list_pieces

# The list has 12 elements, one for each transcript
len(list_pieces)

# Each transcript has been split into 10 pieces of text
len(list_pieces[0])

# Calculate the polarity for each piece of text

polarity_transcript = []
for lp in list_pieces:
    polarity_piece = []
    for p in lp:
        polarity_piece.append(TextBlob(p).sentiment.polarity) #polarity of that piece
    polarity_transcript.append(polarity_piece) #polarities appended of that comedian
    
x=polarity_transcript
x

# Show the plot for one comedian
plt.plot(polarity_transcript[0]) #first comedian
plt.title(data['full_name'].index[0])
plt.show()

# Show the plot for all comedians
plt.rcParams['figure.figsize'] = [16, 12]

for index, comedian in enumerate(data.index):    
    plt.subplot(3, 4, index+1)
    plt.plot(polarity_transcript[index])
    plt.plot(np.arange(0,10), np.zeros(10))
    plt.title(data['full_name'][index])
    plt.ylim(ymin=-.2, ymax=.3)
    
plt.show()

"""#Assignments
1. Classify all comedian accordig to Polarity and Subjectivity.




"""

#1.Classifying by calculating mean of chunks of text for each comedian

#POLARITY
def find_mean(lists):
    means = []
    for lst in lists:
        mean = sum(lst) / len(lst)
        if mean < 0:
            means.append("Negative")
        elif mean == 0:
            means.append("Neutral")  
        else:
            means.append("Positive") 
       
    return means
find_mean(x)    #mean of list_piece polarities

#SUBJECTIVITY
def getAnalysis1(score):
    if (score > 0 and score < 0.5):
     return "Fact"
    elif score == 0:
     return "Neutral"
    else:
     return "Opinion"
data['subjectivity_class'] = data['subjectivity'].apply(getAnalysis1)
data['subjectivity_class']

"""2. Modify the number of sections the comedy routine is split into and see how the charts over time change and again classify all comedian accordig to Polarity and Subjectivity."""

#2.
# Split each routine into 20 parts
import numpy as np
import math

def split_text(text, n=20):
    '''Takes in a string of text and splits into n equal parts, with a default of 10 equal parts.'''

    # Calculate length of text, the size of each chunk of text and the starting points of each chunk of text
    length = len(text)
    size = math.floor(length / n)
    start = np.arange(0, length, size)
    
    # Pull out equally sized pieces of text and put it into a list
    split_list = []
    for piece in range(n):
        split_list.append(text[start[piece]:start[piece]+size])
    return split_list

# Let's create a list to hold all of the pieces of text
list_pieces = []
for t in data.transcript:
    split = split_text(t)
    list_pieces.append(split)
    
list_pieces

# The list has 12 elements, one for each transcript
len(list_pieces)

# Each transcript has been split into 20 pieces of text
len(list_pieces[0])

# Calculate the polarity for each piece of text

polarity_transcript = []
for lp in list_pieces:
    polarity_piece = []
    for p in lp:
        polarity_piece.append(TextBlob(p).sentiment.polarity)
    polarity_transcript.append(polarity_piece)
    
polarity_transcript

def find_mean(lists):
    means = []
    for lst in lists:
        mean = sum(lst) / len(lst)
        if mean < 0:
            means.append("Negative")
        elif mean == 0:
            means.append("Neutral")  
        else:
            means.append("Positive") 
       
    return means
find_mean(x)

# Show the plot for one comedian
plt.plot(polarity_transcript[0])
plt.title(data['full_name'].index[0])
plt.show()

# Show the plot for all comedians
plt.rcParams['figure.figsize'] = [16, 12]

for index, comedian in enumerate(data.index):    
    plt.subplot(3, 4, index+1)
    plt.plot(polarity_transcript[index])
    plt.plot(np.arange(0,10), np.zeros(10))
    plt.title(data['full_name'][index])
    plt.ylim(ymin=-.2, ymax=.4)
    
plt.show()

#FINDINGS

#most positive is mike birbiglia as he is always above the graph axis
#hasan minhaj is mostly posiitve, but get negative in the start.

# 1. Classify all comedian accordig to Polarity and Subjectivity.(First method)
def getAnalysis(score):
    if score < 0:
     return "Negative"
    elif score == 0:
     return "Neutral"
    else:
     return "Positive"
data['polarity_class'] = data['polarity'].apply(getAnalysis)
data['polarity_class']

def getAnalysis1(score):
    if (score > 0 and score < 0.5):
     return "Fact"
    elif score == 0:
     return "Neutral"
    else:
     return "Opinion"
data['subjectivity_class'] = data['subjectivity'].apply(getAnalysis1)
data['subjectivity_class']
#se

data